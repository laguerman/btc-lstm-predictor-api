# scripts/train_classification_model.py

import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
import os

print("Cargando datos para el modelo de clasificaciÃ³n...")
X_train = np.load('data/X_train_clf.npy')
y_train = np.load('data/y_train_clf.npy')
X_test = np.load('data/X_test_clf.npy')
y_test = np.load('data/y_test_clf.npy')

# --- CAMBIOS EN LA ARQUITECTURA Y COMPILACIÃ“N ---
model = Sequential([
    LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),
    Dropout(0.2),
    LSTM(units=50),
    Dropout(0.2),
    # Capa de salida para clasificaciÃ³n binaria
    Dense(units=1, activation='sigmoid') # ðŸ‘ˆ 'sigmoid' para dar una probabilidad
])

# Compilamos con loss y mÃ©tricas para clasificaciÃ³n
model.compile(optimizer='adam', 
              loss='binary_crossentropy', # ðŸ‘ˆ Loss para clasificaciÃ³n
              metrics=['accuracy']) # ðŸ‘ˆ MÃ©trica para ver el % de acierto

early_stop = EarlyStopping(monitor='val_accuracy', mode='max', patience=10, restore_best_weights=True)

print("Iniciando entrenamiento del modelo de clasificaciÃ³n...")
history = model.fit(X_train, y_train, epochs=50, batch_size=32,
                    validation_data=(X_test, y_test),
                    callbacks=[early_stop], verbose=1)

os.makedirs('models', exist_ok=True)
model.save('models/lstm_classification_model.h5')
print("\nâœ… Modelo de clasificaciÃ³n entrenado y guardado.")